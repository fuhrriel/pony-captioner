# Copy this file to .env and customize as needed

# HuggingFace token (optional, for private models)
# Get your token from https://huggingface.co/settings/tokens
# HF_TOKEN=your_token_here

# Model cache directory (default: ./models/huggingface_cache)
# HF_HOME=/models/huggingface_cache
# TRANSFORMERS_CACHE=/models/huggingface_cache

# CUDA visible devices (default: all)
# NVIDIA_VISIBLE_DEVICES=0

# Memory allocation
# Increase if you have more GPU memory available
# PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512

